{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7r4B5t-71nP",
    "outputId": "6d7215a3-f7c2-4739-9834-7d0ddd2e04c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/ooga/.cache/kagglehub/datasets/lakshmi25npathi/bike-sharing-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lakshmi25npathi/bike-sharing-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Q9eRqiVL766j",
    "outputId": "b4362794-3c29-43af-bc11-e471882562de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>2011-04-06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.390833</td>\n",
       "      <td>0.387608</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>0.263063</td>\n",
       "      <td>413</td>\n",
       "      <td>2395</td>\n",
       "      <td>2808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>2011-04-07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.433696</td>\n",
       "      <td>0.602917</td>\n",
       "      <td>0.162312</td>\n",
       "      <td>571</td>\n",
       "      <td>2570</td>\n",
       "      <td>3141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>2011-04-08</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.335833</td>\n",
       "      <td>0.324479</td>\n",
       "      <td>0.836250</td>\n",
       "      <td>0.226992</td>\n",
       "      <td>172</td>\n",
       "      <td>1299</td>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.341529</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.133083</td>\n",
       "      <td>879</td>\n",
       "      <td>1576</td>\n",
       "      <td>2455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>2011-04-10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.426737</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.146767</td>\n",
       "      <td>1188</td>\n",
       "      <td>1707</td>\n",
       "      <td>2895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0         1  2011-01-01       1   0     1        0        6           0   \n",
       "1         2  2011-01-02       1   0     1        0        0           0   \n",
       "2         3  2011-01-03       1   0     1        0        1           1   \n",
       "3         4  2011-01-04       1   0     1        0        2           1   \n",
       "4         5  2011-01-05       1   0     1        0        3           1   \n",
       "..      ...         ...     ...  ..   ...      ...      ...         ...   \n",
       "95       96  2011-04-06       2   0     4        0        3           1   \n",
       "96       97  2011-04-07       2   0     4        0        4           1   \n",
       "97       98  2011-04-08       2   0     4        0        5           1   \n",
       "98       99  2011-04-09       2   0     4        0        6           0   \n",
       "99      100  2011-04-10       2   0     4        0        0           0   \n",
       "\n",
       "    weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0            2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1            2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2            1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3            1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4            1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "..         ...       ...       ...       ...        ...     ...         ...   \n",
       "95           1  0.390833  0.387608  0.470833   0.263063     413        2395   \n",
       "96           1  0.437500  0.433696  0.602917   0.162312     571        2570   \n",
       "97           2  0.335833  0.324479  0.836250   0.226992     172        1299   \n",
       "98           2  0.342500  0.341529  0.877500   0.133083     879        1576   \n",
       "99           2  0.426667  0.426737  0.857500   0.146767    1188        1707   \n",
       "\n",
       "     cnt  \n",
       "0    985  \n",
       "1    801  \n",
       "2   1349  \n",
       "3   1562  \n",
       "4   1600  \n",
       "..   ...  \n",
       "95  2808  \n",
       "96  3141  \n",
       "97  1471  \n",
       "98  2455  \n",
       "99  2895  \n",
       "\n",
       "[100 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('/Users/ooga/.cache/kagglehub/datasets/lakshmi25npathi/bike-sharing-dataset/versions/1/day.csv')\n",
    "df1.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "D-cAVf7IFqD5",
    "outputId": "98c9a21d-b3d3-4ae6-eee1-0ebb1259adba"
   },
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/ooga/venv/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <98D50080-9632-3EA4-B874-146E55453763> /Users/ooga/venv/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libomp.dylib' (no such file), '/opt/homebrew/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libomp.dylib' (no such file)\"]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor, GradientBoostingRegressor\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mXGBRegressor\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.13/site-packages/xgboost/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     Booster,\n\u001b[32m     10\u001b[39m     DataIter,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     build_info,\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.13/site-packages/xgboost/tracker.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, _deprecate_positional_args, make_jcargs\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.13/site-packages/xgboost/core.py:295\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[32m    294\u001b[39m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m _LIB = \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    299\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[32m    300\u001b[39m \n\u001b[32m    301\u001b[39m \u001b[33;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m \u001b[33;03m        return value from API calls\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.13/site-packages/xgboost/core.py:257\u001b[39m, in \u001b[36m_load_lib\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[32m    256\u001b[39m         libname = os.path.basename(lib_paths[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[32m    258\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[33mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) could not be loaded.\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[33mLikely causes:\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[33m  * OpenMP runtime is not installed\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[33m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[33m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[33m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[33m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[32m    266\u001b[39m \n\u001b[32m    267\u001b[39m \u001b[33m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[32m    268\u001b[39m \n\u001b[32m    269\u001b[39m \u001b[33mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    271\u001b[39m         )\n\u001b[32m    272\u001b[39m     _register_log_callback(lib)\n\u001b[32m    274\u001b[39m     libver = _lib_version(lib)\n",
      "\u001b[31mXGBoostError\u001b[39m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/ooga/venv/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <98D50080-9632-3EA4-B874-146E55453763> /Users/ooga/venv/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libomp.dylib' (no such file), '/opt/homebrew/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libomp.dylib' (no such file)\"]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "# Since we have a preview of the data, I'll assume it's loaded from a CSV file\n",
    "# In a real-world scenario, you would need to provide the actual file path\n",
    "df = pd.read_csv('/home/zua/.cache/kagglehub/datasets/lakshmi25npathi/bike-sharing-dataset/versions/1/day.csv')  # Using the daily aggregated data\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nBasic information about the dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "# 1. Distribution of the target variable\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['cnt'], bins=30, kde=True)\n",
    "plt.title('Distribution of Total Bike Rentals')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 2. Rental count by season\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='season', y='cnt', data=df)\n",
    "plt.title('Bike Rentals by Season')\n",
    "plt.xlabel('Season (1:Spring, 2:Summer, 3:Fall, 4:Winter)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 3. Rental count by weather situation\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='weathersit', y='cnt', data=df)\n",
    "plt.title('Bike Rentals by Weather Situation')\n",
    "plt.xlabel('Weather Situation')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 4. Rental count by month\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x='mnth', y='cnt', data=df)\n",
    "plt.title('Bike Rentals by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 5. Rental count by workingday\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='workingday', y='cnt', data=df)\n",
    "plt.title('Bike Rentals by Working Day')\n",
    "plt.xlabel('Working Day (0: Weekend/Holiday, 1: Working Day)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 6. Correlation analysis\n",
    "plt.figure(figsize=(14, 10))\n",
    "# Exclude the 'dteday' column from correlation calculation\n",
    "correlation_matrix = df.drop(columns=['dteday']).corr()  # Exclude 'dteday'\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 7. Scatter plots for numerical features vs. target\n",
    "numerical_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.scatter(df[feature], df['cnt'], alpha=0.5)\n",
    "    plt.title(f'{feature} vs. cnt')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('cnt')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Time series analysis - Rental count over time\n",
    "df['dteday'] = pd.to_datetime(df['dteday'])\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(df['dteday'], df['cnt'])\n",
    "plt.title('Bike Rentals Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Feature Engineering\n",
    "# Convert categorical variables to dummy variables\n",
    "df['season'] = df['season'].astype('category')\n",
    "df['yr'] = df['yr'].astype('category')\n",
    "df['mnth'] = df['mnth'].astype('category')\n",
    "df['holiday'] = df['holiday'].astype('category')\n",
    "df['weekday'] = df['weekday'].astype('category')\n",
    "df['workingday'] = df['workingday'].astype('category')\n",
    "df['weathersit'] = df['weathersit'].astype('category')\n",
    "\n",
    "# Create dummies for categorical variables\n",
    "df_encoded = pd.get_dummies(df, columns=['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit'], drop_first=True)\n",
    "\n",
    "# Prepare data for modeling\n",
    "X = df_encoded.drop(['instant', 'dteday', 'casual', 'registered', 'cnt'], axis=1)\n",
    "y = df_encoded['cnt']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model Building and Evaluation\n",
    "# 1. Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr.predict(X_test_scaled)\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, lr_pred))\n",
    "lr_r2 = r2_score(y_test, lr_pred)\n",
    "lr_mae = mean_absolute_error(y_test, lr_pred)\n",
    "\n",
    "# 2. Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "rf_r2 = r2_score(y_test, rf_pred)\n",
    "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
    "\n",
    "# 3. Gradient Boosting Regressor\n",
    "gb = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "gb_pred = gb.predict(X_test)\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test, gb_pred))\n",
    "gb_r2 = r2_score(y_test, gb_pred)\n",
    "gb_mae = mean_absolute_error(y_test, gb_pred)\n",
    "# 4. XGBoost\n",
    "from xgboost import XGBRegressor # Import the XGBRegressor class from the xgboost module\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
    "xgb_r2 = r2_score(y_test, xgb_pred)\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_pred)\n",
    "\n",
    "# Compare model performance\n",
    "models = ['Linear Regression', 'Random Forest', 'Gradient Boosting', 'XGBoost']\n",
    "rmse_scores = [lr_rmse, rf_rmse, gb_rmse, xgb_rmse]\n",
    "r2_scores = [lr_r2, rf_r2, gb_r2, xgb_r2]\n",
    "mae_scores = [lr_mae, rf_mae, gb_mae, xgb_mae]\n",
    "\n",
    "# Create a DataFrame to compare model performance\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'RMSE': rmse_scores,\n",
    "    'R-squared': r2_scores,\n",
    "    'MAE': mae_scores\n",
    "})\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(model_comparison.sort_values('RMSE'))\n",
    "\n",
    "# Feature importance for the best model (assuming Random Forest or Gradient Boosting performs best)\n",
    "best_model = gb  # Can be updated based on results\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': best_model.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance.head(15))\n",
    "plt.title('Top 15 Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Hyperparameter tuning for the best model\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_gb = grid_search.best_estimator_\n",
    "best_gb.fit(X_train, y_train)\n",
    "best_gb_pred = best_gb.predict(X_test)\n",
    "best_gb_rmse = np.sqrt(mean_squared_error(y_test, best_gb_pred))\n",
    "best_gb_r2 = r2_score(y_test, best_gb_pred)\n",
    "best_gb_mae = mean_absolute_error(y_test, best_gb_pred)\n",
    "\n",
    "print(\"\\nBest Model (Tuned Gradient Boosting) Performance:\")\n",
    "print(f\"RMSE: {best_gb_rmse:.2f}\")\n",
    "print(f\"R-squared: {best_gb_r2:.4f}\")\n",
    "print(f\"MAE: {best_gb_mae:.2f}\")\n",
    "\n",
    "# Visualize actual vs predicted values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_test, best_gb_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted Bike Rentals')\n",
    "plt.show()\n",
    "\n",
    "# Visualize residuals\n",
    "residuals = y_test - best_gb_pred\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(best_gb_pred, residuals, alpha=0.5)\n",
    "plt.hlines(y=0, xmin=residuals.min(), xmax=residuals.max(), colors='r', linestyles='--')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of residuals\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(residuals, bins=30, kde=True)\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Print final conclusions\n",
    "print(\"\\nFinal Model Evaluation:\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"The best performing model is the tuned Gradient Boosting Regressor with an RMSE of {best_gb_rmse:.2f}.\")\n",
    "print(f\"This model explains {best_gb_r2*100:.2f}% of the variance in bike rental counts.\")\n",
    "print(\"\\nMost important features determining bike rentals:\")\n",
    "for i, (feature, importance) in enumerate(zip(feature_importance['Feature'].head(5), feature_importance['Importance'].head(5))):\n",
    "    print(f\"{i+1}. {feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
